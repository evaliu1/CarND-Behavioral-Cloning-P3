{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run all the cells below to make sure everything is working and ready to go. All cells should run without error.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import cv2\n",
    "import os\n",
    "import math\n",
    "from PIL import Image         \n",
    "from os import getcwd\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the images and data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lines= []\n",
    "with open('data/driving_log.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for line in reader:\n",
    "        lines.append(line)\n",
    "        \n",
    "train_samples, validation_samples = train_test_split(lines, test_size=0.05)\n",
    "        \n",
    "#np.random.shuffle(lines)\n",
    "#split_i = int(len(lines) * 0.9)\n",
    "#X_train, y_train = list(zip(*lines[:split_i]))\n",
    "#X_valid, y_valid = list(zip(*lines[split_i:]))\n",
    "\n",
    "\n",
    "#X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "#X_valid, y_valid = np.array(X_valid), np.array(y_valid) \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "662\n",
      "Done Generator\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.misc import imread, imresize\n",
    "\n",
    "# Define the generator function\n",
    "import cv2\n",
    "import numpy as np\n",
    "import sklearn\n",
    "\n",
    "def generator(samples, batch_size=32):\n",
    "    num_samples = len(samples)\n",
    "    while 1: # Loop forever so the generator never terminates\n",
    "        shuffle(samples)\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_samples = samples[offset:offset+batch_size]\n",
    "            images = []\n",
    "            angles = []\n",
    "            for batch_sample in batch_samples:\n",
    "                name = batch_sample[0]\n",
    "                img = mpimg.imread(name)\n",
    "                #res = cv2.resize(img,(16,32,3), interpolation = cv2.INTER_CUBIC)\n",
    "                \n",
    "                center_angle = float(batch_sample[3])\n",
    "                \n",
    "                images.append(img)\n",
    "                angles.append(center_angle)\n",
    "\n",
    "            # trim image to only see section with road\n",
    "            X_train = np.array(images)\n",
    "            y_train = np.array(angles)\n",
    "            yield sklearn.utils.shuffle(X_train, y_train)\n",
    "\n",
    "# compile and train the model using the generator function\n",
    "train_generator = generator(train_samples, batch_size=32)\n",
    "validation_generator = generator(validation_samples, batch_size=32)\n",
    "print(len(validation_samples))\n",
    "print('Done Generator')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the Trainning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lambda_5 (Lambda)                (None, 32, 64, 3)     0           lambda_input_3[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)                (None, 32, 64, 3)     0           lambda_5[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_9 (Convolution2D)  (None, 30, 62, 16)    448         lambda_6[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_10 (Convolution2D) (None, 28, 60, 32)    4640        convolution2d_9[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_11 (Convolution2D) (None, 26, 58, 64)    18496       convolution2d_10[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_12 (Convolution2D) (None, 24, 56, 128)   73856       convolution2d_11[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_3 (MaxPooling2D)    (None, 12, 28, 128)   0           convolution2d_12[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)              (None, 43008)         0           maxpooling2d_3[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dense_9 (Dense)                  (None, 1024)          44041216    flatten_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_7 (Activation)        (None, 1024)          0           dense_9[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_10 (Dense)                 (None, 512)           524800      activation_7[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_8 (Activation)        (None, 512)           0           dense_10[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_11 (Dense)                 (None, 128)           65664       activation_8[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_9 (Activation)        (None, 128)           0           dense_11[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_12 (Dense)                 (None, 1)             129         activation_9[0][0]               \n",
      "====================================================================================================\n",
      "Total params: 44,729,249\n",
      "Trainable params: 44,729,249\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Epoch 1/20\n",
      "12569/12569 [==============================] - 1285s - loss: 0.0908 - acc: 0.8144 - val_loss: 0.0374 - val_acc: 0.8218\n",
      "Epoch 2/20\n",
      "12569/12569 [==============================] - 1337s - loss: 0.0340 - acc: 0.8176 - val_loss: 0.0377 - val_acc: 0.8233\n",
      "Epoch 3/20\n",
      "12569/12569 [==============================] - 1353s - loss: 0.0247 - acc: 0.8223 - val_loss: 0.0333 - val_acc: 0.8202\n",
      "Epoch 4/20\n",
      "12569/12569 [==============================] - 1349s - loss: 0.0182 - acc: 0.8258 - val_loss: 0.0313 - val_acc: 0.8263\n",
      "Epoch 5/20\n",
      "12569/12569 [==============================] - 1348s - loss: 0.0142 - acc: 0.8271 - val_loss: 0.0318 - val_acc: 0.8248\n",
      "Epoch 6/20\n",
      "12569/12569 [==============================] - 1343s - loss: 0.0100 - acc: 0.8288 - val_loss: 0.0358 - val_acc: 0.8157\n",
      "Epoch 7/20\n",
      "12569/12569 [==============================] - 1331s - loss: 0.0079 - acc: 0.8287 - val_loss: 0.0308 - val_acc: 0.8248\n",
      "Epoch 8/20\n",
      "12569/12569 [==============================] - 1338s - loss: 0.0065 - acc: 0.8289 - val_loss: 0.0327 - val_acc: 0.8248\n",
      "Epoch 9/20\n",
      "12569/12569 [==============================] - 1335s - loss: 0.0050 - acc: 0.8291 - val_loss: 0.0324 - val_acc: 0.8233\n",
      "Epoch 10/20\n",
      "12569/12569 [==============================] - 1332s - loss: 0.0045 - acc: 0.8290 - val_loss: 0.0309 - val_acc: 0.8233\n",
      "Epoch 11/20\n",
      "12569/12569 [==============================] - 1333s - loss: 0.0046 - acc: 0.8289 - val_loss: 0.0299 - val_acc: 0.8233\n",
      "Epoch 12/20\n",
      "12569/12569 [==============================] - 1332s - loss: 0.0035 - acc: 0.8291 - val_loss: 0.0294 - val_acc: 0.8248\n",
      "Epoch 13/20\n",
      "12569/12569 [==============================] - 1333s - loss: 0.0028 - acc: 0.8292 - val_loss: 0.0294 - val_acc: 0.8248\n",
      "Epoch 14/20\n",
      "12569/12569 [==============================] - 1336s - loss: 0.0029 - acc: 0.8292 - val_loss: 0.0353 - val_acc: 0.8187\n",
      "Epoch 15/20\n",
      "12569/12569 [==============================] - 1342s - loss: 0.0030 - acc: 0.8290 - val_loss: 0.0315 - val_acc: 0.8248\n",
      "Epoch 16/20\n",
      "12569/12569 [==============================] - 1339s - loss: 0.0039 - acc: 0.8289 - val_loss: 0.0337 - val_acc: 0.8233\n",
      "Epoch 17/20\n",
      "12569/12569 [==============================] - 1339s - loss: 0.0032 - acc: 0.8292 - val_loss: 0.0343 - val_acc: 0.8233\n",
      "Epoch 18/20\n",
      "12569/12569 [==============================] - 1340s - loss: 0.0026 - acc: 0.8291 - val_loss: 0.0345 - val_acc: 0.8248\n",
      "Epoch 19/20\n",
      "12569/12569 [==============================] - 1342s - loss: 0.0021 - acc: 0.8291 - val_loss: 0.0350 - val_acc: 0.8233\n",
      "Epoch 20/20\n",
      "12569/12569 [==============================] - 1337s - loss: 0.0021 - acc: 0.8292 - val_loss: 0.0318 - val_acc: 0.8218\n",
      "Saved model to disk\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, SpatialDropout2D, ELU\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Cropping2D\n",
    "from keras.layers.core import Lambda\n",
    "\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import tensorflow as tf\n",
    "\n",
    "def resize_comma(image):\n",
    "    import tensorflow as tf \n",
    "    return tf.image.resize_images(image, [32,64])\n",
    "\n",
    "model= Sequential()\n",
    "#odel.add(Lambda(lambda x: x/127.5 - 1.,input_shape=(160,320,3)))\n",
    "#odel.add(Lambda(lambda x: (x/255.0-0.5)),input_shape=(160, 320, 1))\n",
    "#odel.add(Cropping2D(cropping=((70, 25), (0, 0))))\n",
    "\n",
    "#model.add(Cropping2D(cropping=((70, 25), (0, 0)),dim_ordering='tf', input_shape=(160, 320, 3)))\n",
    "#model.add(Lambda(lambda x: (x/255.0) - 0.5),input_shape=(160,320,3))\n",
    "\n",
    "# Resize the data\n",
    "model.add(Lambda(resize_comma,input_shape=(160,320,3)))\n",
    "# Normalize the data set\n",
    "model.add(Lambda(lambda x: (x/255.0) - 0.5))\n",
    "\n",
    "#onv2D(16,5,5, input_shape=(32, 16, 1), border_mode='same', activation='relu')\n",
    "model.add(Convolution2D(16,3,3,activation=\"relu\"))\n",
    "model.add(Convolution2D(32,3,3,activation = \"relu\"))\n",
    "\n",
    "model.add(Convolution2D(64,3,3,activation = \"relu\"))\n",
    "model.add(Convolution2D(128,3,3,activation = \"relu\"))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "#model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "#model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(1024))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam',metrics=['accuracy'])\n",
    "model.summary()\n",
    "#model.fit(myTrain,validation_split =0.2, shuffle=True, nb_epoch=3)\n",
    "#model.fit(X_train, Y_train, nb_epoch=3,verbose=1, validation_data=(X_valid, Y_valid))\n",
    "model.fit_generator(train_generator, samples_per_epoch= len(train_samples), validation_data=validation_generator,\n",
    "           nb_val_samples=len(validation_samples), nb_epoch=20)\n",
    "\n",
    "from keras.models import model_from_json\n",
    "\n",
    "#model_json = model.to_json()\n",
    "#with open(\"model-4b.json\", \"w\") as json_file:\n",
    "#    json_file.write(model_json)\n",
    "    \n",
    "#model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")\n",
    "model.save(\"model.h5\")\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
